import os
from functools import cache, cached_property
from pathlib import Path
from typing import Any

from langchain_community.cache import SQLiteCache
from langchain_core.globals import set_llm_cache
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from openinference.instrumentation.langchain import LangChainInstrumentor
from phoenix.otel import register
from pydantic import Field, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict

PATH_CHUNKS = Path("chunks")
DB_INDEX = Path("db_index")


@cache
class Configuration(BaseSettings):
    model_config = SettingsConfigDict(env_file=".env", extra="ignore")

    # Models
    llm_openai_model: str = Field("gpt-4o", description="LLM model from OpenAI")
    embeddings_openai_model: str = Field(
        "text-embedding-3-small",
        description="Embeddings model from OpenAI",
    )

    # API keys
    openai_api_key: str = Field("", description="OpenAI api key")
    llamatrace_api_key: str = Field(
        "", description="Api key for llamatrace with hosting at Phoenix Arize AI"
    )
    llamatrace_project: str = Field(
        "", description="Project name in Phoenix Arize AI. If empty disable tracing"
    )

    # Parameters
    chunk_size: int = Field(500, description="Chunk size for data processing")
    chunk_overlap: int = Field(
        20, description="Number of overlapping characters between chunks"
    )
    similarity_top_k: int = Field(
        5, description="Retriever's final number of returned nodes"
    )

    # Input for development purposes
<<<<<<< HEAD
    cv_path: Path = Field(..., description="Full path to CV")
    job_description: str = Field(..., description="Job description")
=======
    cv_path: Path = Field(
        Path("/home/amarin/Downloads/Alessandro_Marin_PhD_CV.pdf"),
        description="Full path to CV",
    )
    job_description: str = Field(
        """Vi søker to erfarne analytikere med fokus på skybaserte løsninger og maskinlæring
    Vi søker to erfarne data scientists / analytikere med en sterk bakgrunn i å bygge modeller for tekst og tall.
    Du vil jobbe med å utvikle, vedlikeholde og optimalisere maskinlæringsmodeller.
    Dette inkluderer å jobbe med skybaserte løsninger, ved hjelp av teknologier som blant annet Snowflake, DBT og Azure.
    Arbeidsoppgaver:
    Modellbygging:
    Utvikle og optimalisere maskinlæringsmodeller for tekst og tall.
    Modellimplementering:
    Sørge for stabil drift og kontinuerlig optimalisering av modellene i produksjonsmiljøer. 
    Bidra til automatiserte pipeliner
    Overvåkning og vedlikehold:
    Overvåke modellens ytelse og kontinuerlig evaluere prediksjonskvalitet. Du vil også utvikle og vedlikeholde 
    et robust system for varsling og feilretting.
    Skalerbarhet og ytelsesoptimalisering:
    Arbeide for å sikre skalerbare løsninger for maskinlæringsmodellene, tilpasse kapasitet og ytelse i tråd 
    med voksende data- og analysebehov.
    Sikkerhet og compliance:
    Sørge for at modellene overholder gjeldende sikkerhetsstandarder og personvernkrav.
    Tverrfaglig samarbeid:
    Jobbe tett med dataingeniører, analytikere og forretningsfolk for å sikre datatilgjengelighet og -kvalitet, 
    samt støtte analysebaserte beslutningsprosesser.
    Kvalifikasjoner vi ser etter:
    Erfaring med å bygge modeller for tekst og tall.
    Erfaring med databehandling, inkludert skyplattformer som Azure, Snowflake og DevOps-verktøy.
    Kunnskap om verktøy som Snowflake og DBT for datalagring og transformasjon, samt automatiseringsverktøy for effektivisering av arbeidsprosesser.
    Meget god forståelse av datavitenskapelige metoder og teknikker, inkludert prediktive modeller, dyp læring og statistiske analyseverktøy.
    Erfaring med kontinuerlig overvåkning og evaluering av modellytelse, samt feilsøking og problemløsing.
    God evne til å samarbeide med tverrfaglige team og gode kommunikasjonsevner på norsk.
    Vi tilbyr en viktig rolle i utviklingen av våre data- og analysekapasiteter, med muligheten til å forme fremtiden 
    for våre maskinlæringsprosesser. Du vil jobbe tett med et team av dyktige fagpersoner for å drive innovasjon 
    og kontinuerlig forbedring i våre analyseplattformer.""", description="Job description")
>>>>>>> 9dd3c85 (redo)

    @model_validator(mode="before")
    @classmethod
    def validate_cv_path(cls, data: Any) -> Any:
        cv_path = Path(data.get("cv_path", None))
        if cv_path is not None and not cv_path.exists():
            raise ValueError(
                f"{cv_path}: CV does not exist"
            )

        return data

    @property
    def is_tracing(self) -> bool:
        if self.llamatrace_api_key == "":
            if self.llamatrace_project == "":
                return False
            else:
                raise ValueError(
                    "llamatrace project is set but llamatrace api key is empty"
                )
        else:
            if self.llamatrace_project == "":
                return False
            else:
                return True

    @cached_property
    def llm(self) -> bool:
        return ChatOpenAI(model_name=self.llm_openai_model, api_key=self.openai_api_key)

    @cached_property
    def embeddings(self) -> bool:
        return OpenAIEmbeddings(model=self.embeddings_openai_model, api_key=self.openai_api_key)


# class Settings(BaseSettings):
#     config = Configuration()
#     LLM and embeddings
#     llm = ChatOpenAI(model_name=config.llm_openai_model, api_key=config.openai_api_key)
#     embeddings = OpenAIEmbeddings(model=config.embeddings_openai_model, api_key=config.openai_api_key)


def config_cache():
    set_llm_cache(SQLiteCache(database_path=".langchain.db"))


def config_tracing(config: Configuration) -> None:
    if config.is_tracing:
        os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = config.llamatrace_api_key
        os.environ["PHOENIX_CLIENT_HEADERS"] = config.llamatrace_api_key
        os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com"

        tracer_provider = register(project_name=config.llamatrace_project)

        LangChainInstrumentor().instrument(tracer_provider=tracer_provider)
